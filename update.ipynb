{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a script to update the JSON file for the D3 unrealized gains/losses chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the necessary modules and utilities. Make sure that you have these modules in your python environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "from datetime import timedelta as tdelta\n",
    "from yahoo_finance import Share\n",
    "import pandas as pd\n",
    "from dateutil.parser import parse as dtparse\n",
    "import json\n",
    "from pprint import pprint\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create a couple of functions that will create the offset for each box segment start location and sort the values of each day's gains/losses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The offset_list function creates an additional column that computes the start points for the box offset in each day's gains/losses. This will be used to properly stack those gains and losses in the D3 chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def offset_list(ldf):\n",
    "    offset = 0\n",
    "    offsetlist = []\n",
    "    fneg=True\n",
    "    for items in ldf:\n",
    "        if fneg:\n",
    "            if items>0:\n",
    "                offsetlist.append(offset)\n",
    "                offset=np.abs(offset)+np.abs(items)\n",
    "            else:\n",
    "                offset=0\n",
    "                offsetlist.append(offset)\n",
    "                offset=np.abs(offset)+np.abs(items)\n",
    "                fneg=False\n",
    "        else:\n",
    "            offsetlist.append(offset)\n",
    "            offset=np.abs(offset)+np.abs(items)    \n",
    "        return offsetlist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. We first need to send the sorted values of each date entry's gains/losses. In order for the offset to make it so that the maximum values are below the others (in the positive and negative sections), we arrange them so that the values are sorted from maximum to minimum. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sorted_values(pddf,i):\n",
    "    df =  pddf.ix[i].sort_values(ascending=False)\n",
    "    ofsl = offset_list(df)\n",
    "    dfret = pd.DataFrame(columns=['name','value','offset'])\n",
    "    dfret['name'] = df.index\n",
    "    dfret['value'] = list(df)\n",
    "    dfret['offset'] = ofsl\n",
    "    dfret['date'] = df.name\n",
    "    return dfret\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within a given range, we want to know if the market was open on the previous days and back 15 days. We chose one of the oldest stocks and check the return of the historical information for that range. This will return records for data of when the market was open. Instead of only excluding weekend, this will also include bank holidays, for example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yesterday = dt(dt.now().year, dt.now().month, dt.now().day, 12,0,0) - tdelta(1)\n",
    "fiftdback = yesterday - tdelta(15)\n",
    "\n",
    "hist_ED = Share(\"ED\").get_historical(fiftdback.isoformat().split(\"T\")[0],yesterday.isoformat().split(\"T\")[0])\n",
    "\n",
    "newdatelist = []\n",
    "for k in range(len(hist_ED)):\n",
    "        newdatelist.append(hist_ED[len(hist_ED)-(k+1)]['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to compare details about the dates.\n",
    "We want to have populated a JSON file that contains the stock information\n",
    "So we need to compare first the size of the JSON list.\n",
    "1. Assess the following cases:\n",
    "      a. On a new day, does the end-date of the newdatelist increase the range of dates? If so, we need to add new data and subtract from the JSON file.\n",
    "      b. On a new day, does the end-date of the new datelist do nothing to the range of dates? Then we need to do nothing.\n",
    "2. We need to access the dates in the JSON file in order to make this work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('stocks.json') as data_file:    \n",
    "    data = json.load(data_file)\n",
    "\n",
    "current_datelist = []\n",
    "for k in range(len(data)):\n",
    "    current_datelist.append(data[k][str(k)][0]['date'])\n",
    "\n",
    "# 3. Compare the end-dates\n",
    "\n",
    "daydiff = dtparse(newdatelist[-1]) - dtparse(current_datelist[-1])\n",
    "\n",
    "# 4. If the daydiff >=1, then there needs to subtract a day, and advance the day.\n",
    "if (daydiff.days >= 1):\n",
    "    data2 = []\n",
    "    # This will subtract the last entry in the JSON file and move the entries down to\n",
    "    # to make space for the newest entry\n",
    "    for k in range(len(data)-1): \n",
    "        dt2 = {}\n",
    "        dt2[str(k)] = data[k+1][str(k+1)]\n",
    "        data2.append(dt2)\n",
    "\n",
    "    # This will read the list of owned stocks and their value and share prices\n",
    "    stocklist = pd.read_csv(\"stock_list_today.csv\")\n",
    "    stocklist['value'] = stocklist['shareprice']*stocklist['shares']\n",
    "    dfst = stocklist.set_index('name')\n",
    "    df = pd.DataFrame(columns = ['date'])\n",
    "    df['date'] = [newdatelist[-1]]\n",
    "\n",
    "    for stocks in stocklist['name']:\n",
    "        df[stocks] = df['date'].apply(lambda x: np.float(Share(stocks).get_historical(x,x)[0]['Close'])*dfst.transpose()[stocks]['shares'] - dfst.transpose()[stocks]['value'])\n",
    "    df = df.set_index('date')\n",
    "    df = df.sort_index()\n",
    "    df0 = sorted_values(df,0)\n",
    "    df1 =  json.loads(df0.to_json(orient='records'))\n",
    "\n",
    "    for item in df1:\n",
    "        item.pop('date')\n",
    "    df2 = {} ; df2['date'] = json.loads(df0.to_json(orient='records'))[0]['date']\n",
    "    df1.append(df2)\n",
    "    df1.reverse()\n",
    "\n",
    "    df2 = {} ; df2[str(k+1)] = df1\n",
    "    data2.append(df2)\n",
    "    f = open('stocks.json','w')\n",
    "    f.write(json.dumps(data2)) \n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
